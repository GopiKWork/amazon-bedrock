{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Models on Amazon Bedrock\n",
    "\n",
    "This notebook demonstrates the basic functionality of using OpenAI models on Amazon Bedrock through different authentication methods and API patterns.\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Generate short-term Bedrock API keys** for OpenAI compatibility\n",
    "2. **Use OpenAI SDK** with Bedrock endpoints\n",
    "3. **Direct Bedrock InvokeModel** API calls\n",
    "4. **Bedrock Converse API** for multi-turn conversations\n",
    "\n",
    "## Prerequisites\n",
    "- AWS credentials configured\n",
    "- Access to Amazon Bedrock in us-west-2\n",
    "- OpenAI model (gpt-oss-20b) access enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Constants\n",
    "\n",
    "First, let's import the required libraries and set up our constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-west-2\n",
      "Model: openai.gpt-oss-20b-1:0\n",
      "Sample Vehicle: 2020 Toyota Camry\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import openai\n",
    "from datetime import timedelta\n",
    "from aws_bedrock_token_generator import provide_token\n",
    "\n",
    "# Constants\n",
    "REGION = \"us-west-2\"  # AWS region for Bedrock\n",
    "MODEL_ID = \"openai.gpt-oss-20b-1:0\"  # OpenAI model on Bedrock\n",
    "\n",
    "# Sample automotive diagnostic scenario\n",
    "VEHICLE_DATA = {\n",
    "    \"make\": \"Toyota\",\n",
    "    \"model\": \"Camry\", \n",
    "    \"year\": 2020,\n",
    "    \"mileage\": 45000,\n",
    "    \"symptoms\": [\"engine noise during acceleration\", \"reduced fuel efficiency\"],\n",
    "    \"error_codes\": [\"P0171\", \"P0174\"]\n",
    "}\n",
    "\n",
    "print(f\"Region: {REGION}\")\n",
    "print(f\"Model: {MODEL_ID}\")\n",
    "print(f\"Sample Vehicle: {VEHICLE_DATA['year']} {VEHICLE_DATA['make']} {VEHICLE_DATA['model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Short-Term Bedrock API Key\n",
    "\n",
    "The first step is to generate a temporary API key that allows OpenAI SDK compatibility with Bedrock. This key:\n",
    "- Expires in 1 hour for security\n",
    "- Is based on your current AWS role/credentials\n",
    "- Contains a base64-encoded presigned URL for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current AWS identity\n",
    "sts_client = boto3.client('sts', region_name=REGION)\n",
    "identity = sts_client.get_caller_identity()\n",
    "role_arn = identity['Arn']\n",
    "\n",
    "\n",
    "\n",
    "# Generate short-term API key with explicit 1-hour expiry\n",
    "api_key = provide_token(\n",
    "    region=REGION,\n",
    "    expiry=timedelta(hours=1)\n",
    ")\n",
    "\n",
    "# Mask API key for security - only show last 8 characters\n",
    "masked_key = \"XXX...\" + api_key[-8:] if len(api_key) > 8 else \"XXX...\"\n",
    "\n",
    "\n",
    "# Decode and analyze the token structure for educational purposes\n",
    "prefix = \"bedrock-api-key-\"\n",
    "if api_key.startswith(prefix):\n",
    "    encoded_part = api_key[len(prefix):]\n",
    "    \n",
    "    \n",
    "# Decode the base64 to get the presigned URL\n",
    "decoded_url = base64.b64decode(encoded_part).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(decoded_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OpenAI SDK with Bedrock\n",
    "\n",
    "Now let's use the generated API key with the OpenAI SDK, configured to point to Bedrock endpoints. This allows you to use familiar OpenAI patterns while leveraging Bedrock's infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Chat Completion with Bedrock\n",
      "Sending diagnostic request...\n",
      "\n",
      "Diagnostic Analysis:\n",
      "==================================================\n",
      "<reasoning>The user wants a diagnostic analysis: 2020 Toyota Camry, 45,000 miles, engine noise during acceleration, reduced fuel efficiency. Error codes P0171 (System too lean: bank 1) and P0174 (System too lean: bank 2). Provide analysis, possible causes, recommended actions, urgency level. Must consider typical 2020 Camry. Could be 2.5L 4-cylinder or 3.5L V6. Likely 2.5L. Engine noise during acceleration could be misfire, or low timing, or EGR, or wrong fuel pressure. Reduced fuel efficiency plus lean codes indicates low fuel or high air. Could be vacuum leak, clogged MAP, dirty idle air control, throttle body, or mass airflow sensor reading incorrectly. Also could be fuel pump or fuel filter.\n",
      "\n",
      "We need to cover the \"engine noise\" - misfire, knocking, rough idle. Could be due to lean mixture causing misfires. The codes indicate lean mixture on both banks. Could be due to vacuum leaks, intake manifold gasket, throttle body leak, or evaporative emissions system leaks. Another cause: faulty fuel injectors, low fuel pressure. Could be a faulty fuel pressure regulator. Also, could be a bad EGR valve causing too much air. Or a faulty MAF sensor causing incorrect readings.\n",
      "\n",
      "Also, the 2020 Camry may have a \"Variable Valve Timing\" system. If the timing is off due to a malfunctioning cam timing belt or the Camshaft Position Sensor, could cause misfires and noise. But lean codes specifically.\n",
      "\n",
      "Also, the \"engine noise during acceleration\" could be due to the engine knocking due to low spark timing or high compression. But lean codes - more likely misfire. So the noise could be a misfire or rough running.\n",
      "\n",
      "Reduced fuel efficiency: lean mixture reduces fuel consumption but also reduces power. So the engine might be running lean, causing misfires, noise, and less fuel efficiency.\n",
      "\n",
      "Possible causes: Vacuum leak (intake manifold gasket, throttle body, vacuum hoses), clogged MAP, dirty MAF sensor, faulty fuel pump or low fuel pressure, failed fuel injector, throttle body stuck open, EGR valve stuck open, faulty oxygen sensor causing incorrect fueling feedback, faulty Mass Air Flow sensor, faulty pressure sensor, or faulty PCV system. Also, a bad coolant temperature sensor could mislead fueling.\n",
      "\n",
      "Also, due to a miscalibrated throttle</reasoning>\n",
      "\n",
      " Tokens used: 637\n"
     ]
    }
   ],
   "source": [
    "# Configure OpenAI client for Bedrock with correct endpoint\n",
    "client = openai.OpenAI(\n",
    "    base_url=f\"https://bedrock-runtime.{REGION}.amazonaws.com/openai/v1\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Create a diagnostic prompt for our automotive scenario\n",
    "diagnostic_prompt = f\"\"\"You are a senior automotive diagnostic technician. Analyze this vehicle issue:\n",
    "\n",
    "Vehicle: {VEHICLE_DATA['year']} {VEHICLE_DATA['make']} {VEHICLE_DATA['model']}\n",
    "Mileage: {VEHICLE_DATA['mileage']} miles\n",
    "Symptoms: {', '.join(VEHICLE_DATA['symptoms'])}\n",
    "Error Codes: {', '.join(VEHICLE_DATA['error_codes'])}\n",
    "\n",
    "Please provide:\n",
    "1. Analysis of the problem\n",
    "2. Possible causes\n",
    "3. Recommended actions\n",
    "4. Urgency level (low/medium/high)\"\"\"\n",
    "\n",
    "print(\"OpenAI Chat Completion with Bedrock\")\n",
    "print(\"Sending diagnostic request...\")\n",
    "\n",
    "# Send chat completion request\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": diagnostic_prompt}\n",
    "    ],\n",
    "    max_completion_tokens=500,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Display response\n",
    "print(\"\\nDiagnostic Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "if response.choices and response.choices[0].message:\n",
    "    print(response.choices[0].message.content)\n",
    "    \n",
    "    if response.usage:\n",
    "        print(f\"\\n Tokens used: {response.usage.total_tokens}\")\n",
    "else:\n",
    "    print(f\"Full response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Direct Bedrock InvokeModel API\n",
    "\n",
    "This approach uses the native AWS Bedrock API directly with boto3, bypassing the OpenAI SDK. It uses your AWS credentials directly and demonstrates the raw Bedrock API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Bedrock InvokeModel API\n",
      "\n",
      " Sending diagnostic request...\n",
      "\n",
      " Diagnostic Analysis:\n",
      "==================================================\n",
      "<reasoning>We need to respond as a senior automotive diagnostic technician. The vehicle is a 2020 Toyota Camry, 45k miles. Symptoms: engine noise during acceleration, reduced fuel efficiency. Error codes: P0171 (System too lean, Bank 1) and P0174 (System too lean, Bank 2). Provide analysis, possible causes, recommended actions, urgency level.\n",
      "\n",
      "We should mention that P0171/4 indicate lean condition. Engine noise during acceleration could be due to misfire or rough idle, but lean condition can cause increased exhaust temperatures, misfire, and noise. Reduced fuel efficiency matches lean mixture.\n",
      "\n",
      "Possible causes: vacuum leaks, faulty MAF or MAP sensor, throttle body, idle air control valve, fuel injector problem, fuel pressure regulator, faulty fuel pump, bad O2 sensor, poor fuel quality, evaporative emissions system leak, throttle position sensor, air intake system. Also could be due to incorrect fuel trim, miscalibrations.\n",
      "\n",
      "Recommended actions: Visual inspection of vacuum hoses, check MAF sensor cleaning, check throttle body, check for leaks in intake, inspect O2 sensors, inspect fuel pump and fuel pressure regulator, test fuel pressure. Check for any pending codes. Check for misfire codes. Clean MAF, replace if necessary. Inspect and replace faulty sensors. Relearn throttle position. Check for any vacuum leaks. If fuel pump is weak, replace. Consider vacuum leak test. Check for any stuck idle air control valve. Check for fuel injector performance.\n",
      "\n",
      "Also mention to clear codes after repairs.\n",
      "\n",
      "Urgency: medium. Lean condition can lead to engine damage if left. Engine noise indicates possible misfire. Not immediate danger but could cause damage. So medium urgency.\n",
      "\n",
      "We need to provide bullet points. Let's produce a thorough response.</reasoning>**2020 Toyota Camry – Diagnostic Summary**\n",
      "\n",
      "| Item | Details |\n",
      "|------|---------|\n",
      "| **Mileage** | 45 000 mi |\n",
      "| **Symptoms** | 1. Engine noise during acceleration (likely a rough, knocking or “hissing” sound) <br>2. Noticeable drop in fuel economy |\n",
      "| **Codes** | P0171 – System Too Lean, Bank 1 <br>P0174 – System Too Lean, Bank 2 |\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Analysis of the Problem\n",
      "\n",
      "- **Lean Condition (P0171/4)** – Both banks are reporting a lean mixture, which means the\n",
      "\n",
      " Tokens used: 637\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bedrock runtime client\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=REGION)\n",
    "\n",
    "print(\"AWS Bedrock InvokeModel API\")\n",
    "print(\"\\n Sending diagnostic request...\")\n",
    "\n",
    "# Prepare request body in OpenAI format (Bedrock supports OpenAI format for these models)\n",
    "request_body = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": diagnostic_prompt}\n",
    "    ],\n",
    "    \"max_completion_tokens\": 500,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "# Invoke model using native Bedrock API\n",
    "response = bedrock_client.invoke_model(\n",
    "    modelId=MODEL_ID,\n",
    "    body=json.dumps(request_body),\n",
    "    contentType='application/json'\n",
    ")\n",
    "\n",
    "# Parse response\n",
    "response_body = json.loads(response['body'].read())\n",
    "\n",
    "# Display response\n",
    "print(\"\\n Diagnostic Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "if 'choices' in response_body and response_body['choices']:\n",
    "    print(response_body['choices'][0]['message']['content'])\n",
    "    \n",
    "    if 'usage' in response_body:\n",
    "        print(f\"\\n Tokens used: {response_body['usage']['total_tokens']}\")\n",
    "else:\n",
    "    print(json.dumps(response_body, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bedrock Converse API\n",
    "\n",
    "The Converse API is Bedrock's native conversation interface that supports multi-turn dialogues. It's designed for building conversational applications and maintains context across turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Bedrock Converse API\n",
      "Sending diagnostic request...\n",
      "\n",
      "Initial Diagnostic Analysis:\n",
      "==================================================\n",
      "[Model reasoning]: We need to respond as a senior automotive diagnostic technician, analyze the issue: 2020 Toyota Camry, 45k miles, symptoms: engine noise during acceleration, reduced fuel efficiency, error codes P0171 (System too lean (Bank 1)), P0174 (System too lean (Bank 2)). Provide analysis of problem, possible...\n",
      "\n",
      " Follow-up Question: What would be the estimated cost to fix these issues?\n",
      "\n",
      "Cost Estimate:\n",
      "==================================================\n",
      "Below is a **ball‑park cost guide** for the most common repairs that would address the P0171/P0174 (lean‑bank) codes and the “engine noise during acceleration” symptom.  \n",
      "All figures are **range estimates** (parts + labor) for a 2020 Toyota Camry (1.5‑L or 2.5‑L 4‑cyl). Exact costs will vary by shop, region, and whether the problem is a single component or a multi‑step fix.\n",
      "\n",
      "| # | Likely Fix | Typical Parts | Typical Labor | Total Estimate |\n",
      "|---|------------|---------------|---------------|----------------|\n",
      "| **1** | **Fuel Rail/Pressure Sensor (or Fuel Pump) replacement** | OEM sensor or fuel pump ($80–$200) |\n",
      "\n",
      "Tokens used: 468\n"
     ]
    }
   ],
   "source": [
    "print(\"AWS Bedrock Converse API\")\n",
    "print(\"Sending diagnostic request...\")\n",
    "\n",
    "# First conversation turn - diagnostic analysis\n",
    "response = bedrock_client.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": diagnostic_prompt}]\n",
    "        }\n",
    "    ],\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 500,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display first response\n",
    "print(\"\\nInitial Diagnostic Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'output' in response and 'message' in response['output']:\n",
    "    content = response['output']['message']['content']\n",
    "    # Find the text content (skip reasoning content)\n",
    "    for item in content:\n",
    "        if 'text' in item and item['text'].strip():\n",
    "            first_response = item['text']\n",
    "            print(first_response)\n",
    "            break\n",
    "    else:\n",
    "        # If no text content, try reasoning content\n",
    "        for item in content:\n",
    "            if 'reasoningContent' in item and 'reasoningText' in item['reasoningContent']:\n",
    "                reasoning_text = item['reasoningContent']['reasoningText']['text']\n",
    "                print(f\"[Model reasoning]: {reasoning_text[:300]}...\")\n",
    "                first_response = \"I analyzed your vehicle's diagnostic codes and symptoms.\"\n",
    "                break\n",
    "        else:\n",
    "            print(\"No displayable content found\")\n",
    "else:\n",
    "    print(\"Unexpected response format\")\n",
    "\n",
    "# Second conversation turn - follow-up question\n",
    "follow_up_question = \"What would be the estimated cost to fix these issues?\"\n",
    "\n",
    "print(f\"\\n Follow-up Question: {follow_up_question}\")\n",
    "\n",
    "response = bedrock_client.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [{\"text\": diagnostic_prompt}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"text\": first_response}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": follow_up_question}]\n",
    "        }\n",
    "    ],\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 300,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display follow-up response\n",
    "print(\"\\nCost Estimate:\")\n",
    "print(\"=\" * 50)\n",
    "content = response['output']['message']['content']\n",
    "# Find the text content (skip reasoning content)\n",
    "for item in content:\n",
    "    if 'text' in item:\n",
    "        print(item['text'])\n",
    "        break\n",
    "\n",
    "print(f\"\\nTokens used: {response['usage']['totalTokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-70fa5d36\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"content\":\"<reasoning>We need to respond with JSON: {\\\"vehicle_id\\\": \\\"<string>\\\", \\\"error_code\\\": \\\"<string>\\\", \\\"problem\\\": \\\"<string>\\\", \\\"recommended_action\\\": \\\"<string>\\\"}. Provide vehicle_id: maybe \\\"Honda Accord 2018\\\" or some ID. Use vehicle_id: \\\"Honda Accord 2018\\\". error_code: \\\"P0401\\\". problem: description of issue. recommended_action: recommended action. Provide in JSON. Ensure valid JSON.</reasoning>{\\\"vehicle_id\\\":\\\"Honda Accord 2018\\\",\\\"error_code\\\":\\\"P0401\\\",\\\"problem\\\":\\\"The engine control module (ECM) has detected a malfunction in the Exhaust Gas Recirculation (EGR) system, indicating that the EGR valve is not functioning properly or the EGR control circuit is not operating within the expected parameters.\\\",\\\"recommended_action\\\":\\\"Inspect the EGR valve for proper operation, clean or replace it if clogged or stuck. Check the EGR valve solenoid and associated wiring for damage or poor connections. Verify the EGR temperature sensor and related sensors. After repairs, clear the fault code and perform a drive cycle to ensure the issue is resolved.\\\"}\",\"role\":\"assistant\"}}],\"created\":1756238901,\"model\":\"openai.gpt-oss-20b-1:0\",\"service_tier\":\"standard\",\"system_fingerprint\":\"fp_a4ee6ca3d4\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":234,\"prompt_tokens\":109,\"total_tokens\":343}}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a maintenance assistant. Provide vehicle diagnostic details in the following structured JSON format: \"\n",
    "            '{\"vehicle_id\": \"<string>\", \"error_code\": \"<string>\", \"problem\": \"<string>\", \"recommended_action\": \"<string>\"}'\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Vehicle: Honda Accord 2018\\nError code: P0401\\n\"\n",
    "            \"Describe the issue and recommended action in the JSON format above.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,  \n",
    "    \"messages\": messages,\n",
    "    \"max_completion_tokens\": 512,\n",
    "    \"temperature\": 0.2,\n",
    "}\n",
    "\n",
    "body_bytes = json.dumps(payload).encode(\"utf-8\")\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    modelId=MODEL_ID,\n",
    "    body=body_bytes\n",
    ")\n",
    "\n",
    "result = response['body'].read().decode()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vehicle_id': 'Honda Accord 2018', 'error_code': 'P0401', 'problem': 'The engine control module (ECM) has detected a malfunction in the Exhaust Gas Recirculation (EGR) system, indicating that the EGR valve is not functioning properly or the EGR control circuit is not operating within the expected parameters.', 'recommended_action': 'Inspect the EGR valve for proper operation, clean or replace it if clogged or stuck. Check the EGR valve solenoid and associated wiring for damage or poor connections. Verify the EGR temperature sensor and related sensors. After repairs, clear the fault code and perform a drive cycle to ensure the issue is resolved.'}\n"
     ]
    }
   ],
   "source": [
    "reason_token_end = '</reasoning>'\n",
    "message = json.loads(result)\n",
    "message = message['choices'][0]['message']['content']\n",
    "message = message[message.find(reason_token_end) + len(reason_token_end):]\n",
    "message = json.loads(message)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated four different ways to use OpenAI models on Amazon Bedrock:\n",
    "\n",
    "1. **🔑 API Key Generation**: Created temporary credentials for OpenAI SDK compatibility\n",
    "2. **🔧 OpenAI SDK**: Used familiar OpenAI patterns with Bedrock endpoints\n",
    "3. **⚡ InvokeModel API**: Direct Bedrock API calls with AWS credentials\n",
    "4. **💬 Converse API**: Native Bedrock conversation interface with multi-turn support\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Flexibility**: Multiple authentication and API patterns available\n",
    "- **Security**: Short-term tokens and AWS credential-based access\n",
    "- **Compatibility**: OpenAI SDK works seamlessly with Bedrock\n",
    "- **Native Features**: Bedrock Converse API provides advanced conversation capabilities\n",
    "\n",
    "### Next Steps:\n",
    "- Explore the advanced agent implementations in the next notebook\n",
    "- Try different OpenAI models available on Bedrock\n",
    "- Implement your own use cases using these patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
