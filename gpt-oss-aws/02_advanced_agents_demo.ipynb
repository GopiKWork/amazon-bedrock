{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced AI Agents with OpenAI Models on Bedrock\n",
    "\n",
    "This notebook demonstrates advanced agent architectures using Strands and LangGraph frameworks with OpenAI models on Amazon Bedrock.\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Strands Agent Framework** - Tool-enabled agents with automotive diagnostic capabilities\n",
    "2. **LangGraph Workflow Agents** - State-based agents with complex workflows\n",
    "3. **Real Tool Integration** - Agents that can read files, calculate costs, and analyze data\n",
    "4. **Automotive Use Cases** - Practical diagnostic report analysis\n",
    "\n",
    "## Prerequisites\n",
    "- Completed the basic demonstrations notebook\n",
    "- AWS credentials configured\n",
    "- Strands and LangGraph frameworks installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Constants\n",
    "\n",
    "Let's import the required libraries and set up our constants for the advanced agent demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-west-2\n",
      "Model: openai.gpt-oss-20b-1:0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for agent frameworks\n",
    "import boto3\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Constants\n",
    "REGION = \"us-west-2\"  # AWS region for Bedrock\n",
    "MODEL_ID = \"openai.gpt-oss-20b-1:0\"  # OpenAI model on Bedrock\n",
    "\n",
    "print(f\"Region: {REGION}\")\n",
    "print(f\"Model: {MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Diagnostic Report\n",
    "\n",
    "Let's create a sample automotive diagnostic report that our agents will analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample diagnostic report created\n",
      "Vehicle: 2019 Toyota Camry with lean mixture issues\n"
     ]
    }
   ],
   "source": [
    "# Create sample diagnostic report content\n",
    "diagnostic_report = \"\"\"AUTOMOTIVE DIAGNOSTIC REPORT\n",
    "=============================\n",
    "\n",
    "Vehicle Information:\n",
    "- Make: Toyota\n",
    "- Model: Camry\n",
    "- Year: 2019\n",
    "- Mileage: 78,500 miles\n",
    "- Customer: John Smith\n",
    "\n",
    "Reported Issues:\n",
    "- Engine making unusual noise during acceleration\n",
    "- Check engine light intermittently on\n",
    "- Reduced fuel economy (15% decrease)\n",
    "- Rough idle when cold starting\n",
    "\n",
    "OBD-II Scan Results:\n",
    "- P0171: System Too Lean (Bank 1)\n",
    "- P0174: System Too Lean (Bank 2)\n",
    "- P0300: Random/Multiple Cylinder Misfire\n",
    "\n",
    "Recommended Repairs:\n",
    "1. Replace cracked vacuum hose - $25 parts + $50 labor\n",
    "2. Replace air filter - $15 parts + $20 labor\n",
    "3. Replace spark plugs (set of 4) - $40 parts + $80 labor\n",
    "4. Clean MAF sensor - $10 cleaning + $30 labor\n",
    "\n",
    "Total Estimate: $270 + tax\n",
    "\n",
    "Technician: Sarah Williams\"\"\"\n",
    "\n",
    "# Write to file for agents to read\n",
    "with open('diagnostic_report.txt', 'w') as f:\n",
    "    f.write(diagnostic_report)\n",
    "\n",
    "print(\"Sample diagnostic report created\")\n",
    "print(\"Vehicle: 2019 Toyota Camry with lean mixture issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Strands Agent Framework\n",
    "\n",
    "Let's create a Strands agent with automotive diagnostic tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strands framework imports\n",
    "from strands.models import BedrockModel\n",
    "from strands.agent import Agent\n",
    "from strands.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strands agent created with diagnostic tools\n"
     ]
    }
   ],
   "source": [
    "# Define Strands agent tools\n",
    "@tool\n",
    "def read_diagnostic_report(file_path: str = \"diagnostic_report.txt\") -> str:\n",
    "    \"\"\"Read diagnostic report file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def calculate_repair_cost(parts: float, labor_hours: float, rate: float = 120.0) -> dict:\n",
    "    \"\"\"Calculate total repair cost.\"\"\"\n",
    "    labor = labor_hours * rate\n",
    "    subtotal = parts + labor\n",
    "    tax = subtotal * 0.085\n",
    "    total = subtotal + tax\n",
    "    return {\n",
    "        \"parts\": parts,\n",
    "        \"labor\": labor,\n",
    "        \"tax\": round(tax, 2),\n",
    "        \"total\": round(total, 2)\n",
    "    }\n",
    "\n",
    "# Create Strands agent\n",
    "boto_session = boto3.Session(region_name=REGION)\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=MODEL_ID,\n",
    "    boto_session=boto_session,\n",
    "    model_kwargs={\n",
    "        \"inferenceConfig\": {\n",
    "            \"maxTokens\": 1000,\n",
    "            \"temperature\": 0.3,\n",
    "            \"topP\": 0.8\n",
    "        }\n",
    "    },\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "strands_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=\"You are an automotive service advisor. Use tools to analyze diagnostic reports and provide recommendations.\",\n",
    "    tools=[read_diagnostic_report, calculate_repair_cost]\n",
    ")\n",
    "\n",
    "print(\"Strands agent created with diagnostic tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Strands Agent:\n",
      "Request: Please read my diagnostic report and calculate the total repair cost. What's wrong with my car?\n",
      "\n",
      "==================================================\n",
      "The user wants to read diagnostic report and calculate total repair cost. So we need to read file. Use read_diagnostic_report. Then parse. Likely there are parts and labor. Since we don't know parts or labor from report. Let's just call read_diagnostic_report.<reasoning>The user wants to read diagnostic report and calculate total repair cost. So we need to read file. Use read_diagnostic_report. Then parse. Likely there are parts and labor. Since we don't know parts or labor from report. Let's just call read_diagnostic_report.</reasoning>\n",
      "Tool #1: read_diagnostic_report\n",
      "Response:\n",
      "<reasoning>The user wants to read diagnostic report and calculate total repair cost. So we need to read file. Use read_diagnostic_report. Then parse. Likely there are parts and labor. Since we don't know parts or labor from report. Let's just call read_diagnostic_report.</reasoning>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Strands agent\n",
    "request = \"Please read my diagnostic report and calculate the total repair cost. What's wrong with my car?\"\n",
    "\n",
    "print(\"Testing Strands Agent:\")\n",
    "print(f\"Request: {request}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "response = strands_agent(request)\n",
    "print(\"Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LangGraph Workflow Agent\n",
    "\n",
    "Now let's create a LangGraph agent with a structured workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph framework imports\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.tools import tool as langchain_tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition, ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph workflow agent created\n"
     ]
    }
   ],
   "source": [
    "# Define LangGraph tools\n",
    "@langchain_tool\n",
    "def read_report_file(file_path: str = \"diagnostic_report.txt\") -> str:\n",
    "    \"\"\"Read diagnostic report file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@langchain_tool\n",
    "def analyze_error_codes(codes: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Analyze OBD-II error codes.\"\"\"\n",
    "    descriptions = {\n",
    "        \"P0171\": \"System Too Lean (Bank 1)\",\n",
    "        \"P0174\": \"System Too Lean (Bank 2)\",\n",
    "        \"P0300\": \"Random/Multiple Cylinder Misfire\"\n",
    "    }\n",
    "    return {code: descriptions.get(code, \"Unknown code\") for code in codes}\n",
    "\n",
    "# Create LangGraph workflow\n",
    "llm = ChatBedrockConverse(\n",
    "    model_id=MODEL_ID,\n",
    "    region_name=REGION,\n",
    "    temperature=0.3,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "tools = [read_report_file, analyze_error_codes]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    sys_msg = SystemMessage(content=\"You are an automotive expert. Use tools to analyze reports.\")\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Build workflow graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "langgraph_agent = builder.compile()\n",
    "\n",
    "print(\"LangGraph workflow agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LangGraph Agent:\n",
      "Request: Please read my diagnostic report and explain the error codes. What repairs are needed?\n",
      "\n",
      "==================================================\n",
      "Response:\n",
      "AUTOMOTIVE DIAGNOSTIC REPORT\n",
      "=============================\n",
      "\n",
      "Vehicle Information:\n",
      "- Make: Toyota\n",
      "- Model: Camry\n",
      "- Year: 2019\n",
      "- Mileage: 78,500 miles\n",
      "- Customer: John Smith\n",
      "\n",
      "Reported Issues:\n",
      "- Engine making unusual noise during acceleration\n",
      "- Check engine light intermittently on\n",
      "- Reduced fuel economy (15% decrease)\n",
      "- Rough idle when cold starting\n",
      "\n",
      "OBD-II Scan Results:\n",
      "- P0171: System Too Lean (Bank 1)\n",
      "- P0174: System Too Lean (Bank 2)\n",
      "- P0300: Random/Multiple Cylinder Misfire\n",
      "\n",
      "Recommended Repairs:\n",
      "1. Replace cracked vacuum hose - $25 parts + $50 labor\n",
      "2. Replace air filter - $15 parts + $20 labor\n",
      "3. Replace spark plugs (set of 4) - $40 parts + $80 labor\n",
      "4. Clean MAF sensor - $10 cleaning + $30 labor\n",
      "\n",
      "Total Estimate: $270 + tax\n",
      "\n",
      "Technician: Sarah Williams\n"
     ]
    }
   ],
   "source": [
    "# Test LangGraph agent\n",
    "request = \"Please read my diagnostic report and explain the error codes. What repairs are needed?\"\n",
    "\n",
    "print(\"Testing LangGraph Agent:\")\n",
    "print(f\"Request: {request}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "messages = [HumanMessage(content=request)]\n",
    "result = langgraph_agent.invoke({\"messages\": messages})\n",
    "\n",
    "# Get final response\n",
    "for message in reversed(result[\"messages\"]):\n",
    "    if hasattr(message, 'content') and message.content and not hasattr(message, 'tool_calls'):\n",
    "        print(\"Response:\")\n",
    "        print(message.content)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated advanced AI agent architectures:\n",
    "\n",
    "### Strands Framework:\n",
    "- Simple tool-enabled agent architecture\n",
    "- Direct model integration with BedrockModel\n",
    "- Easy tool binding and execution\n",
    "\n",
    "### LangGraph Framework:\n",
    "- Structured workflow with nodes and edges\n",
    "- State management across conversation turns\n",
    "- Conditional routing between assistant and tools\n",
    "\n",
    "Both frameworks successfully analyzed the automotive diagnostic report and provided professional recommendations using OpenAI models on Amazon Bedrock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
