{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Automotive Damage Assessment Demo\n",
    "\n",
    "This notebook demonstrates multimodal indexing patterns using automotive damage assessment data. It shows how to process both text descriptions and images of vehicle damage using different AI processing patterns.\n",
    "\n",
    "## Features demonstrated:\n",
    "- **Text Pattern**: Processes written damage descriptions\n",
    "- **Hybrid Pattern**: Combines photos with text descriptions\n",
    "- **Full Embedding Pattern**: Creates unified understanding of images and text\n",
    "- **Describe Pattern**: Generates text descriptions from photos\n",
    "- **Summarize Pattern**: Condenses lengthy reports into key points\n",
    "\n",
    "## Prerequisites:\n",
    "- AWS credentials configured\n",
    "- S3 Vector permissions\n",
    "- Damage photos in the images/ folder\n",
    "- Sample damage data in JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the setup script to configure imports\n",
    "%run setup_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for notebook\n",
    "from typing import Dict, Any, List\n",
    "import json\n",
    "from IPython.display import Image, display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "print(\"✅ Notebook setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Sample Data\n",
    "\n",
    "Let's examine the automotive damage data we'll be working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_damage_data():\n",
    "    \"\"\"Load the multimodal damage data from JSON file.\"\"\"\n",
    "    data = load_json_data(MULTIMODAL_DAMAGE_DATA_FILE)\n",
    "    return data['damage_cases']\n",
    "\n",
    "def load_dealer_escalation_text():\n",
    "    \"\"\"Load the dealer escalation text for summarize pattern.\"\"\"\n",
    "    return load_text_data(DEALER_ESCALATION_FILE)\n",
    "\n",
    "def get_image_path(damage_id):\n",
    "    \"\"\"Get the path to the damage image.\"\"\"\n",
    "    return os.path.join(IMAGES_DIR, f\"{damage_id}.jpeg\")\n",
    "\n",
    "# Load the data\n",
    "damage_cases = load_damage_data()\n",
    "dealer_escalation_text = load_dealer_escalation_text()\n",
    "\n",
    "print(f\"Loaded {len(damage_cases)} damage cases\")\n",
    "print(f\"Dealer escalation text: {len(dealer_escalation_text):,} characters\")\n",
    "\n",
    "# Display first damage case\n",
    "print(\"\\nFirst damage case:\")\n",
    "case = damage_cases[0]\n",
    "print(f\"ID: {case['id']}\")\n",
    "print(f\"Vehicle: {case['metadata']['vehicle_year']} {case['metadata']['vehicle_make']} {case['metadata']['vehicle_model']}\")\n",
    "print(f\"Damage Type: {case['metadata']['damage_type']}\")\n",
    "print(f\"Estimated Cost: ${case['metadata']['estimated_cost']}\")\n",
    "print(f\"Description: {case['damage_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Damage Images\n",
    "\n",
    "Let's look at the actual damage photos we'll be processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few damage images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Sample Automotive Damage Photos', fontsize=16)\n",
    "\n",
    "for i, case in enumerate(damage_cases[:6]):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    image_path = get_image_path(case['id'])\n",
    "    \n",
    "    try:\n",
    "        # Load and display image\n",
    "        img = PILImage.open(image_path)\n",
    "        axes[row, col].imshow(img)\n",
    "        axes[row, col].set_title(f\"{case['id']}\\n{case['metadata']['vehicle_make']} {case['metadata']['vehicle_model']}\")\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        # Print image description\n",
    "        print(f\"{case['id']}: {case['image_description']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        axes[row, col].text(0.5, 0.5, f\"Image not found\\n{case['id']}\", \n",
    "                           ha='center', va='center', transform=axes[row, col].transAxes)\n",
    "        axes[row, col].axis('off')\n",
    "        print(f\"{case['id']}: Image not found - {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MMIngestor with Image Processing\n",
    "\n",
    "Set up the multimodal ingestor with image resizing for automotive photos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mm_ingestor():\n",
    "    \"\"\"Create MMIngestor with image resizing for automotive photos.\"\"\"\n",
    "    vector_bucket_name, object_bucket_name, index_name = get_standard_names()\n",
    "    \n",
    "    mm_ingestor = MMIngestor(\n",
    "        index_name=index_name,\n",
    "        region_name=REGION_NAME\n",
    "    )\n",
    "    \n",
    "    # Configure image resizer for automotive damage photos\n",
    "    mm_ingestor.preprocessor_chain.clear()\n",
    "    image_resizer = ImageResizer(\n",
    "        target_size=(512, 384),\n",
    "        preserve_aspect_ratio=True\n",
    "    )\n",
    "    mm_ingestor.add_preprocessor(image_resizer)\n",
    "    \n",
    "    print(f\"MMIngestor created with {len(mm_ingestor.pattern_engine.list_patterns())} patterns: {mm_ingestor.pattern_engine.list_patterns()}\")\n",
    "    \n",
    "    return mm_ingestor\n",
    "\n",
    "# Create the ingestor\n",
    "mm_ingestor = create_mm_ingestor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Dealer Escalation Text for Summarize Pattern\n",
    "\n",
    "The summarize pattern works with longer text documents. Let's look at the dealer escalation case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Dealer Escalation Case (for Summarize Pattern) ===\")\n",
    "print(f\"Length: {len(dealer_escalation_text):,} characters\")\n",
    "print(\"\\nContent preview:\")\n",
    "print(dealer_escalation_text[:500] + \"...\")\n",
    "\n",
    "# Show the full text in a scrollable area\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"height: 300px; overflow-y: scroll; border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;\">\n",
    "<h4>Full Dealer Escalation Text:</h4>\n",
    "<pre style=\"white-space: pre-wrap;\">{dealer_escalation_text}</pre>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Dealer Escalation Document (Summarize Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_dealer_escalation():\n",
    "    \"\"\"Ingest dealer escalation text using summarize pattern.\"\"\"\n",
    "    print(\"=== Ingesting Dealer Escalation Document ===\")\n",
    "    \n",
    "    print(f\"Loaded dealer escalation text: {len(dealer_escalation_text):,} characters\")\n",
    "    \n",
    "    # Use summarize pattern for long document\n",
    "    doc_id = mm_ingestor.ingest(\n",
    "        content={'text': dealer_escalation_text},\n",
    "        metadata={\n",
    "            'document_type': 'dealer_escalation',\n",
    "            'category': 'customer_service',\n",
    "            'dealer': 'Lakeside Honda',\n",
    "            'customer': 'Mrs. Janet T.',\n",
    "            'vehicle': '2021 Honda Civic EX',\n",
    "            'case_id': '2024-0934'\n",
    "        },\n",
    "        pattern=\"summarize\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Ingested dealer escalation document: {doc_id}\")\n",
    "    return doc_id\n",
    "\n",
    "# Ingest the dealer escalation document\n",
    "dealer_doc_id = ingest_dealer_escalation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_damage_cases():\n",
    "    \"\"\"Ingest automotive damage cases using different patterns.\"\"\"\n",
    "    print(\"=== Ingesting Automotive Damage Cases ===\")\n",
    "    \n",
    "    print(f\"Loaded {len(damage_cases)} damage cases\")\n",
    "    \n",
    "    # Use different patterns for each case\n",
    "    patterns_to_use = [\"text\", \"hybrid\", \"full_embedding\", \"describe\", \"summarize\", \"text\"]\n",
    "    ingested_docs = []\n",
    "    \n",
    "    for i, case in enumerate(damage_cases):\n",
    "        pattern = patterns_to_use[i]\n",
    "        image_path = get_image_path(case['id'])\n",
    "        \n",
    "        # Extend text for summarize pattern (needs 1000+ characters)\n",
    "        if pattern == \"summarize\":\n",
    "            case_text = case['damage_text'] + \" \" + \"\"\"\n",
    "            Additional detailed assessment: The damage assessment was conducted by certified technicians \n",
    "            following industry standard procedures. The inspection revealed multiple areas of concern \n",
    "            that require immediate attention. The structural integrity of the vehicle has been evaluated \n",
    "            and documented according to insurance guidelines. Repair estimates include both parts and \n",
    "            labor costs based on current market rates. The vehicle owner has been notified of all \n",
    "            findings and recommended repair procedures. All documentation has been submitted to the \n",
    "            insurance carrier for processing and approval. The repair facility has been selected \n",
    "            based on certification and availability. Timeline for repairs depends on parts availability \n",
    "            and shop scheduling. Customer satisfaction and safety remain our top priorities throughout \n",
    "            the entire repair process. Quality assurance checks will be performed at each stage.\n",
    "            The assessment includes detailed photographic documentation of all damage areas, measurements\n",
    "            of affected components, and evaluation of potential safety implications. All work will be\n",
    "            performed according to manufacturer specifications and industry best practices.\n",
    "            \"\"\"\n",
    "        else:\n",
    "            case_text = case['damage_text']\n",
    "        \n",
    "        vehicle = f\"{case['metadata']['vehicle_year']} {case['metadata']['vehicle_make']} {case['metadata']['vehicle_model']}\"\n",
    "        \n",
    "        metadata = {\n",
    "            'damage_id': case['id'],\n",
    "            'vehicle_make': case['metadata']['vehicle_make'],\n",
    "            'vehicle_model': case['metadata']['vehicle_model'],\n",
    "            'vehicle_year': case['metadata']['vehicle_year'],\n",
    "            'damage_type': case['metadata']['damage_type'],\n",
    "            'severity': case['metadata']['severity'],\n",
    "            'estimated_cost': case['metadata']['estimated_cost']\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nProcessing {case['id']}: {vehicle} using {pattern} pattern\")\n",
    "        \n",
    "        # Display the image being processed\n",
    "        if pattern in [\"hybrid\", \"full_embedding\", \"describe\"]:\n",
    "            try:\n",
    "                display(Image(image_path, width=200))\n",
    "                print(f\"Image: {case['image_description']}\")\n",
    "            except:\n",
    "                print(f\"Image not found: {image_path}\")\n",
    "        \n",
    "        print(f\"Text: {case_text[:100]}...\")\n",
    "        \n",
    "        try:\n",
    "            if pattern in [\"hybrid\", \"full_embedding\", \"describe\"]:\n",
    "                doc_id = mm_ingestor.ingest(content={'text': case_text, 'image': image_path}, metadata=metadata, pattern=pattern)\n",
    "            else:  # text and summarize patterns\n",
    "                doc_id = mm_ingestor.ingest(content={'text': case_text}, metadata=metadata, pattern=pattern)\n",
    "            \n",
    "            ingested_docs.append(doc_id)\n",
    "            print(f\"✓ Successfully ingested as: {doc_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nSuccessfully ingested {len(ingested_docs)} damage cases\")\n",
    "    return ingested_docs\n",
    "\n",
    "# Ingest all damage cases\n",
    "damage_docs = ingest_damage_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Examples and Results Analysis\n",
    "\n",
    "Now let's demonstrate search functionality and analyze the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_search_results(results: List[Dict[str, Any]], query: str):\n",
    "    \"\"\"Print search results in a clean format with detailed analysis.\"\"\"\n",
    "    print(f\"\\n🔍 Query: '{query}'\")\n",
    "    print(f\"Found {len(results)} results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        metadata = result.get('metadata', {})\n",
    "        pattern = metadata.get('pattern', 'unknown')\n",
    "        score = result['similarity_score']\n",
    "        \n",
    "        print(f\"\\n{i}. Score: {score:.3f} | Pattern: {pattern}\")\n",
    "        \n",
    "        if 'vehicle_make' in metadata and 'vehicle_model' in metadata:\n",
    "            vehicle = f\"{metadata.get('vehicle_year', '')} {metadata['vehicle_make']} {metadata['vehicle_model']}\"\n",
    "            damage_type = metadata.get('damage_type', '').replace('_', ' ').title()\n",
    "            cost = metadata.get('estimated_cost', 'N/A')\n",
    "            print(f\"   🚗 Vehicle: {vehicle}\")\n",
    "            print(f\"   💥 Damage: {damage_type}\")\n",
    "            print(f\"   💰 Cost: ${cost}\")\n",
    "        \n",
    "        if 'document_type' in metadata:\n",
    "            doc_type = metadata['document_type'].replace('_', ' ').title()\n",
    "            print(f\"   📄 Document: {doc_type}\")\n",
    "            if 'dealer' in metadata:\n",
    "                print(f\"   🏢 Dealer: {metadata['dealer']}\")\n",
    "            if 'case_id' in metadata:\n",
    "                print(f\"   🔢 Case ID: {metadata['case_id']}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Search Example 1: Honda damage\n",
    "print(\"=== Search Example 1: Honda Damage ===\")\n",
    "query1 = \"Honda bumper damage\"\n",
    "results1 = mm_ingestor.search(query={'text': query1}, top_k=3)\n",
    "print_search_results(results1, query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Example 2: Dashboard warning lights (should find dealer escalation)\n",
    "print(\"=== Search Example 2: Dashboard Warning Lights ===\")\n",
    "query2 = \"dashboard warning lights\"\n",
    "results2 = mm_ingestor.search(query={'text': query2}, top_k=3)\n",
    "print_search_results(results2, query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Example 3: Collision damage with metadata filter\n",
    "print(\"=== Search Example 3: Collision Damage (with metadata filter) ===\")\n",
    "query3 = \"collision damage\"\n",
    "results3 = mm_ingestor.search(\n",
    "    text=query3,\n",
    "    metadata_filters={'damage_type': 'collision_damage'},\n",
    "    top_k=3\n",
    ")\n",
    "print_search_results(results3, query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Example 4: High-cost repairs\n",
    "print(\"=== Search Example 4: Expensive Repairs ===\")\n",
    "query4 = \"expensive repair high cost damage\"\n",
    "results4 = mm_ingestor.search(query={'text': query4}, top_k=4)\n",
    "print_search_results(results4, query4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query S3 Vector Metadata and Show Storage Details\n",
    "\n",
    "Let's examine what's actually stored in the S3 Vector Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "from utils import get_standard_names\n",
    "\n",
    "def show_s3_vector_metadata():\n",
    "    \"\"\"Query and display S3 Vector Store metadata.\"\"\"\n",
    "    vector_bucket_name, object_bucket_name, index_name = get_standard_names()\n",
    "    index_name = index_name[index_name.find(\"/\") +1 :]\n",
    "    print(f'vector_bucket_name: {vector_bucket_name}')\n",
    "    print(f'object_bucket_name: {object_bucket_name}')\n",
    "    print(f'index_name: {index_name}')\n",
    "    \n",
    "    # Initialize S3 Vectors client\n",
    "    s3_vectors_client = boto3.client('s3vectors', region_name=REGION_NAME)\n",
    "    \n",
    "    try:\n",
    "        # List vectors in the index\n",
    "        response = s3_vectors_client.list_vectors(\n",
    "            vectorBucketName=vector_bucket_name,\n",
    "            indexName=index_name,\n",
    "            maxResults=20\n",
    "        )\n",
    "        \n",
    "        print(f\"=== S3 Vector Store Contents ===\")\n",
    "        print(f\"Bucket: {vector_bucket_name}\")\n",
    "        print(f\"Index: {index_name}\")\n",
    "        print(f\"Total vectors found: {len(response.get('vectors', []))}\")\n",
    "        \n",
    "        # Display metadata for each vector\n",
    "        for i, vector_info in enumerate(response.get('vectors', []), 1):\n",
    "            vector_key = vector_info['key']\n",
    "            \n",
    "            # Get detailed vector information\n",
    "            vector_details = s3_vectors_client.get_vectors(\n",
    "                vectorBucketName=vector_bucket_name,\n",
    "                indexName=index_name,\n",
    "                keys=[vector_key],\n",
    "                returnMetadata=True\n",
    "            )\n",
    "            \n",
    "            if vector_details.get('vectors'):\n",
    "                vector_data = vector_details['vectors'][0]\n",
    "                metadata = vector_data.get('metadata', {})\n",
    "                \n",
    "                print(f\"\\n{i}. Vector Key: {vector_key}\")\n",
    "                print(f\"   Metadata Tags: {len(metadata)} items\")\n",
    "                \n",
    "                # Show key metadata\n",
    "                for key, value in metadata.items():\n",
    "                    if isinstance(value, str) and len(value) > 50:\n",
    "                        print(f\"   {key}: {value[:50]}...\")\n",
    "                    else:\n",
    "                        print(f\"   {key}: {value}\")\n",
    "                \n",
    "                # Check for S3 object references\n",
    "                if 's3_object_key' in metadata:\n",
    "                    print(f\"   📁 S3 Object: s3://{object_bucket_name}/{metadata['s3_object_key']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying S3 Vector Store: {e}\")\n",
    "\n",
    "# Show S3 Vector Store contents\n",
    "show_s3_vector_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Analysis Summary\n",
    "\n",
    "Let's analyze how each multimodal pattern performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_patterns():\n",
    "    \"\"\"Analyze the performance and characteristics of different patterns.\"\"\"\n",
    "    \n",
    "    patterns_used = [\"text\", \"hybrid\", \"full_embedding\", \"describe\", \"summarize\", \"text\"]\n",
    "    \n",
    "    print(\"=== Multimodal Pattern Analysis ===\")\n",
    "    print()\n",
    "    \n",
    "    pattern_descriptions = {\n",
    "        \"text\": {\n",
    "            \"description\": \"Processes only text descriptions using standard text embeddings\",\n",
    "            \"use_case\": \"When you have detailed written damage reports\",\n",
    "            \"pros\": [\"Fast processing\", \"Good for text-heavy documents\", \"Lower resource usage\"],\n",
    "            \"cons\": [\"Misses visual information\", \"Limited to text content only\"]\n",
    "        },\n",
    "        \"hybrid\": {\n",
    "            \"description\": \"Combines text and image processing with separate embeddings\",\n",
    "            \"use_case\": \"When you have both photos and descriptions of damage\",\n",
    "            \"pros\": [\"Leverages both text and visual info\", \"Good search across modalities\"],\n",
    "            \"cons\": [\"More complex processing\", \"Requires both text and images\"]\n",
    "        },\n",
    "        \"full_embedding\": {\n",
    "            \"description\": \"Creates unified embeddings from both text and images\",\n",
    "            \"use_case\": \"For comprehensive multimodal understanding\",\n",
    "            \"pros\": [\"Single unified representation\", \"Best cross-modal search\"],\n",
    "            \"cons\": [\"Most resource intensive\", \"Complex embedding process\"]\n",
    "        },\n",
    "        \"describe\": {\n",
    "            \"description\": \"Generates text descriptions from images, then processes as text\",\n",
    "            \"use_case\": \"When you have images but limited text descriptions\",\n",
    "            \"pros\": [\"Extracts info from images\", \"Creates searchable text from visuals\"],\n",
    "            \"cons\": [\"Dependent on image description quality\", \"May miss nuanced details\"]\n",
    "        },\n",
    "        \"summarize\": {\n",
    "            \"description\": \"Condenses long documents into key points before embedding\",\n",
    "            \"use_case\": \"For lengthy reports, case files, or documentation\",\n",
    "            \"pros\": [\"Handles long documents\", \"Focuses on key information\"],\n",
    "            \"cons\": [\"May lose detailed information\", \"Requires substantial text input\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for pattern, info in pattern_descriptions.items():\n",
    "        print(f\"🔧 {pattern.upper()} PATTERN\")\n",
    "        print(f\"   Description: {info['description']}\")\n",
    "        print(f\"   Best Use Case: {info['use_case']}\")\n",
    "        print(f\"   ✅ Pros: {', '.join(info['pros'])}\")\n",
    "        print(f\"   ⚠️  Cons: {', '.join(info['cons'])}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=== Pattern Selection Guidelines ===\")\n",
    "    print(\"• Use TEXT for pure text documents (reports, descriptions)\")\n",
    "    print(\"• Use HYBRID when you have both good text and images\")\n",
    "    print(\"• Use FULL_EMBEDDING for the best cross-modal search experience\")\n",
    "    print(\"• Use DESCRIBE when images are your primary data source\")\n",
    "    print(\"• Use SUMMARIZE for long documents that need condensing\")\n",
    "\n",
    "# Run pattern analysis\n",
    "analyze_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive search - modify this cell to try your own queries\n",
    "custom_query = \"severe damage expensive repair\"\n",
    "custom_results = mm_ingestor.search(query={'text': custom_query}, top_k=5)\n",
    "print_search_results(custom_results, custom_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a search with metadata filtering\n",
    "filtered_query = \"vehicle damage\"\n",
    "filtered_results = mm_ingestor.search(\n",
    "    text=filtered_query, \n",
    "    metadata_filters={'vehicle_make': 'Honda'},\n",
    "    top_k=3\n",
    ")\n",
    "print_search_results(filtered_results, f\"{filtered_query} (Honda only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "This notebook demonstrated the power of multimodal AI processing for automotive damage assessment:\n",
    "\n",
    "### What We Accomplished:\n",
    "1. **Processed Real Damage Photos**: Combined visual and textual information from actual automotive damage cases\n",
    "2. **Multiple AI Patterns**: Demonstrated 5 different processing approaches for various use cases\n",
    "3. **Semantic Search**: Found relevant damage cases using natural language queries\n",
    "4. **Metadata Integration**: Combined AI-powered search with structured data filtering\n",
    "5. **Document Summarization**: Processed lengthy dealer escalation cases into searchable summaries\n",
    "\n",
    "### Real-World Applications:\n",
    "- **Insurance Claims Processing**: Automatically categorize and route damage claims\n",
    "- **Repair Cost Estimation**: Find similar historical cases for accurate pricing\n",
    "- **Quality Control**: Identify patterns in damage types and repair outcomes\n",
    "- **Customer Service**: Quickly find relevant cases and solutions for customer inquiries\n",
    "- **Training Data**: Build comprehensive databases for training adjusters and technicians\n",
    "\n",
    "### Technical Benefits:\n",
    "- **Scalable Processing**: Handle thousands of damage cases efficiently\n",
    "- **Flexible Search**: Natural language queries work better than keyword matching\n",
    "- **Rich Metadata**: Combine AI insights with structured business data\n",
    "- **Multiple Modalities**: Process text, images, and documents in a unified system\n",
    "\n",
    "### Next Steps:\n",
    "- Integrate with claims management systems\n",
    "- Add more sophisticated image analysis\n",
    "- Implement automated damage severity scoring\n",
    "- Build conversational interfaces for adjusters and customers\n",
    "- Create automated reporting and analytics dashboards\n",
    "\n",
    "This multimodal approach transforms how automotive businesses can process, understand, and act on damage-related information, making operations more efficient and customer experiences more responsive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
